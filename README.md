# ğŸ¤– Predicting Diabetes with Machine Learning

This project was built as part of my machine learning journey. The goal was to build a complete ML pipeline to predict diabetes using real-world health data from the **BRFSS 2015** dataset. It includes data cleaning, preprocessing, model comparison, and performance evaluation.

---

## ğŸ“Œ Project Overview

- **Objective:** Predict whether an individual has diabetes based on diagnostic health indicators.
- **Dataset:** Behavioral Risk Factor Surveillance System (BRFSS) 2015
- **Workflow:** Data Exploration â†’ Preprocessing â†’ Model Training â†’ Evaluation
- **Models Used:** Logistic Regression, Decision Tree, Random Forest, XGBoost
- **Best Model:** XGBoost with 83.6% Accuracy and 0.795870 F1-Score

---

## ğŸ—‚ï¸ Dataset

The dataset includes the following medical features:

- Age  
- Body Mass Index (BMI)  
- HbA1c Level  
- Blood Glucose Level  
- Physical and mental health indicators  
- Smoking, alcohol, and exercise habits  
- And other relevant diagnostic attributes  

---

## ğŸ” What I Did

- ğŸ§¹ **Data Cleaning:** Removed duplicates, verified class balance  
- ğŸ“Š **Exploratory Data Analysis (EDA):** Visualized distributions and key features  
- âš™ï¸ **Preprocessing:** 
  - Scaled features using `StandardScaler`  
  - Encoded categorical data with `ColumnTransformer`  
  - Used `Pipeline` to streamline preprocessing and modeling  
- ğŸ¤– **Model Training:** Trained and tested four classifiers  
- ğŸ“ˆ **Model Evaluation:** Accuracy, Precision, Recall, F1-Score, ROC-AUC  
- ğŸ§ª **Overfitting Check:** Compared train vs test performance  
- ğŸ§® **Training Size Impact:** Evaluated model accuracy with different train sizes

---

## âœ… Results

After evaluating all four models, hereâ€™s the final performance comparison:

| **Model**              | **Accuracy** | **F1-Score** |
|------------------------|--------------|--------------|
| XGBoost                | 83.6%        | 0.795870     |
| Logistic Regression    | 83.3%        | 0.789844     |
| Random Forest          | 82.4%        | 0.787020     |
| Decision Tree          | 73.9%        | 0.746779     |

ğŸ” **XGBoost** showed the best overall performance, achieving the highest accuracy and F1-Score among all tested models.

---

## ğŸ“Š Visuals Included

- ğŸ“Œ Feature distribution plots  
- ğŸ“Œ Confusion matrices for all models  
- ğŸ“Œ Model performance comparison  
- ğŸ“Œ F1-Score vs. Training Data Size graph  

---

## âš™ï¸ Technologies Used

- Python  
- Jupyter Notebook  
- Pandas, NumPy  
- Seaborn, Matplotlib  
- Scikit-learn  
- XGBoost  

---

## ğŸš€ Getting Started

To run the project locally:

---

### 1. Clone the repository

```bash
git clone https://github.com/talhanadeem-7/Diabetes_Prediction_with_ML

---

### 2. Open the code

Open the project in **VS Code** or any editor of your choice.

---

### 3. Install dependencies

```bash
pip install -r requirements.txt

---

### 4. Load the dataset

Place your dataset file (e.g., `diabetes_prediction_dataset.csv`) in the root directory.

---

### 5. Run the notebook

Launch the Jupyter Notebook and run all cells:

```bash
jupyter notebook Diabetes_Prediction.ipynb
